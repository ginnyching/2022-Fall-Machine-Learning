# -*- coding: utf-8 -*-
"""source.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12tRDHyNJiKPfvMvBK7Yn3hBZHltvTeLt

## HW1: Logistic regression and Linear Regression using Gradient Descent
In hw1, you need to implement linear regression by using only numpy, then train your implemented model by the provided dataset and test the performance with testing data

Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling sklearn.linear_model.LinearRegression
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Part 1. Linear regression model

## Load regression data
"""

x_train, x_test, y_train, y_test = np.load(
    'regression_data.npy', allow_pickle=True)

plt.plot(x_train, y_train, '.')
plt.plot(x_test, y_test, '.')
# len(x_train)=y_train=750,len(y_test)=x_test=250
# print(type(x_test))
# nd.array

"""## Train your model 
### Pseudo code:
1. Random initialize the weights, intercepts of the linear model

**for i in range(iteration)**

    2. Feed foward the training data into the model, get the output prediction
    3. Calculating training loss by Mean Square Error of predcition and ground truth data
    4. Calculating the gradients
    5. Updating the weights and intercepts by the gradients * learning rate 
    
**End of training**
"""


def MSE_gradient_descent(x, y):
    # initialize weight, intercept, learning_rate and iterate
    weight = np.random.uniform(-5, 5)  # beta1
    intercept = np.random.uniform(-5, 5)  # beta0
    learning_rate = 0.01
    iterate = 1000
    loss = []

    for i in range(iterate):
        partial_weight = 0
        partial_intercept = 0
        cost = 0
        for j in range(len(x)):
            # calculate and store the y_prediction
            y_pred = intercept+weight*x[j]
            # calculate loss of MSE
            cost += (y[j]-y_pred)**2
            # partial derivative with respect to weight and intercept
            partial_weight += -2 * x[j] * (y[j] - (intercept + weight * x[j]))
            partial_intercept += -2 * (y[j] - intercept + weight * x[j])
        # update loss, weight, intercept
        loss.append(cost/len(x))
        weight = weight-learning_rate*partial_weight/len(x)
        intercept = intercept-learning_rate*partial_intercept/len(x)
    return weight, intercept, loss


"""## Test the performance on the testing data
Inference the test data (x_test) by your model and calculate the loss of (y_test, y_pred)
"""

train_weight, train_intercept, train_loss = MSE_gradient_descent(
    x_train, y_train)

test_weight, test_intercept, test_loss = MSE_gradient_descent(x_test, y_test)

train_y_pred = train_intercept+train_weight*x_train

test_y_pred = test_intercept+test_weight*x_test

# plot the regression data
plt.title('Regression Data')
plt.plot(x_train, y_train, '.', label='train_data')
#plt.plot(x_test, y_test, '.', label='test_data')
plt.plot(x_train, train_y_pred, 'red', label='train_regression')
#plt.plot(x_test, test_y_pred, 'black', label='test_regression')
plt.legend()
plt.show()

# calculate the cost of MSE


def Mean_square_error(y_train, y_pred):
    cost = 0
    for y1, y2 in zip(y_train, y_pred):
        cost += (y1-y2)**2/len(y_train)
    return cost


print("Mean Square Error=", Mean_square_error(y_train, train_y_pred))
print("Weight=", train_weight)
print("Intercept= ", train_intercept)
plt.title('Learning Curve')
plt.xlabel('iterations')
plt.ylabel('loss')
plt.plot(np.arange(1, len(train_loss) + 1), train_loss, label='train_loss')
#plt.plot(np.arange(1, len(test_loss) + 1), test_loss, label='test_loss')
plt.legend()
plt.show()

"""# Part 2. Logistic regreesion model

## Load classification data
"""

x_train, x_test, y_train, y_test = np.load(
    'classification_data.npy', allow_pickle=True)

plt.scatter(x_train, np.ones_like(x_train), c=y_train)

"""## Train your model 
### Pseudo code:
1. Random initialize the weights, intercepts of the linear model

**for i in range(iteration)**

    2. Feed foward the training data into the model, get the output prediction
    3. Calculating training loss by Cross entrooy Error of predcition and ground truth data
    4. Calculating the gradients
    5. Updating the weights and intercepts by the gradients * learning rate 
    
**End of training**
"""


def sigmoid(x):
    return 1 / (1 + np.exp(-x))


"""Hypothesis from linear regression: $z_{\theta}(x)=\theta_{0}x_{0}+\theta_{1}x_{1}+...+\theta_{n}x_{n}=\theta^{T}x$

Logistic hypothesis from composition of sigmoid/logistic function and linear hypothesis:$h_{\theta}(x)=\frac{1}{1+e^{-z\theta(x)}}=\frac{1}{1+e^{-\theta^{T}x}}$

cost=$-\frac{1}{m}\sum_{i=0}^{m}[y^{(i)}log(h_\theta(x)^{(i)})+(1-y^{(i)})log(1-h_\theta(x)^{(i)})]$
"""


def compute_cost(theta, x, y):
    # hypothesis
    y_pred = sigmoid(np.dot(x, theta))
    # cost
    error = (y * np.log(y_pred)) + ((1 - y) * np.log(1 - y_pred))
    cost = -sum(error)/len(y)
    gradient = np.dot(x.transpose(), (y_pred - y))/len(y)
    return cost[0], gradient


# include intercept
x = np.append(np.ones((len(x_train), 1)), x_train, axis=1)
# reshape y_train from (750,)->(750,1)
y = y_train.reshape(len(x_train), 1)
# initialize theta value
theta_init = np.zeros((2, 1))

# implementation of gradient descent


def gradient_descent(x, y, theta, learning_rate):
    costs = []
    iterations = 200
    for i in range(iterations):
        cost, gradient = compute_cost(theta, x, y)
        theta -= (learning_rate * gradient)
        costs.append(cost)
    return theta, costs


theta, costs = gradient_descent(x, y, theta_init, 1)

y_pred = sigmoid(np.dot(x, theta))
# print(y_pred[0])
# print(y[0])


def cross_entropy_loss(y_pred, y):
    cost = 0
    for i in range(len(y)):
        if y[i] == 1:
            cost += -np.log(y_pred[0])
        else:
            cost += -np.log(1 - y_pred[0])

    return cost/len(y)


cost = cross_entropy_loss(y_pred, y)

print("Weight:", theta[0])
print("Intercept:", theta[1])
print("Cross Entropy Error:", cost)
plt.plot(costs, label='train_loss')
plt.xlabel("Iterations")
plt.ylabel("loss")
plt.title("learning curve")
plt.legend()
plt.show()
